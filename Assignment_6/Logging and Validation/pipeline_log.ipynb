{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fb54855-1b90-41b7-bb5a-126fbb7ec1c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9743b79a-4f20-4091-8af2-63776c9d69ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_ts = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db0489b2-0ad0-4a1c-8ec5-58768417d942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_and_print(layer, table_name, metric_type, metric_value):\n",
    "    # Print to notebook\n",
    "    print(f\"[{layer.upper()}] {table_name} | {metric_type}: {metric_value}\")\n",
    "\n",
    "    # Persist to Delta log table\n",
    "    spark.createDataFrame(\n",
    "        [(run_ts, layer, table_name, metric_type, metric_value)],\n",
    "        [\"run_timestamp\", \"layer\", \"table_name\", \"metric_type\", \"metric_value\"]\n",
    "    ).write.mode(\"append\").saveAsTable(\"pipeline_data_quality_log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "691695ca-8cf4-4796-a4b4-3500cff0fe15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_tables = [\n",
    "    \"bronze_sales_transactions\",\n",
    "    \"bronze_product_master\",\n",
    "    \"bronze_store_region\"\n",
    "]\n",
    "\n",
    "print(\"\\n\uD83D\uDD39 BRONZE LAYER COUNTS\")\n",
    "for table in bronze_tables:\n",
    "    count = spark.table(table).count()\n",
    "    log_and_print(\"bronze\", table, \"record_count\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "952d41b0-5c02-4970-8ea6-11f454189ebc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDD39 SILVER LAYER COUNTS\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8275285343330475>, line 10\u001B[0m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m table \u001B[38;5;129;01min\u001B[39;00m silver_tables:\n",
       "\u001B[1;32m      9\u001B[0m     count \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mtable(table)\u001B[38;5;241m.\u001B[39mcount()\n",
       "\u001B[0;32m---> 10\u001B[0m     log_and_print(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msilver\u001B[39m\u001B[38;5;124m\"\u001B[39m, table, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecord_count\u001B[39m\u001B[38;5;124m\"\u001B[39m, count)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'log_and_print' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'log_and_print' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'log_and_print' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "NOTEBOOK_USER_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KAN00",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8275285343330475>, line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m table \u001B[38;5;129;01min\u001B[39;00m silver_tables:\n\u001B[1;32m      9\u001B[0m     count \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mtable(table)\u001B[38;5;241m.\u001B[39mcount()\n\u001B[0;32m---> 10\u001B[0m     log_and_print(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msilver\u001B[39m\u001B[38;5;124m\"\u001B[39m, table, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecord_count\u001B[39m\u001B[38;5;124m\"\u001B[39m, count)\n",
        "\u001B[0;31mNameError\u001B[0m: name 'log_and_print' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "silver_tables = [\n",
    "    \"silver_sales_transactions\",\n",
    "    \"silver_product_master\",\n",
    "    \"silver_store_region\"\n",
    "]\n",
    "\n",
    "print(\"\\n\uD83D\uDD39 SILVER LAYER COUNTS\")\n",
    "for table in silver_tables:\n",
    "    count = spark.table(table).count()\n",
    "    log_and_print(\"silver\", table, \"record_count\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d8f3902-5c93-49b0-aca4-d80b3a880d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gold_tables = [\n",
    "    \"gold_daily_sales_summary\",\n",
    "    \"gold_monthly_revenue_by_region\",\n",
    "    \"gold_product_performance\"\n",
    "]\n",
    "\n",
    "print(\"\\n\uD83D\uDD39 GOLD LAYER COUNTS\")\n",
    "for table in gold_tables:\n",
    "    count = spark.table(table).count()\n",
    "    log_and_print(\"gold\", table, \"record_count\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "553e79a7-db38-4dd8-9efd-128203eedb47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rejected_df = (\n",
    "    spark.table(\"silver_sales_quarantine\")\n",
    "    .groupBy(\"rejection_reason\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "for row in rejected_df.collect():\n",
    "    reason = row[\"rejection_reason\"]\n",
    "    count = row[\"count\"]\n",
    "\n",
    "    log_and_print(\n",
    "        \"silver\",\n",
    "        \"silver_sales_quarantine\",\n",
    "        f\"rejected_{reason}\",\n",
    "        count\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7346988327064086,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "pipeline_log",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}